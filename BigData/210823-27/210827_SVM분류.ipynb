{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서포트 벡터 머신_분류\n",
    "- 유방암 결과를 분류하는 서포트 벡터 머신 모델을 만들고 predict method를 이용하여 목표변수의 범주를 예측하라. 그리고 모델의 정확도와 confusion matrix을 구하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 공통 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "# train, test를 분할하기 위한 함수\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트(맑은 고딕) 적용\n",
    "matplotlib.rc(\"font\", family = \"Malgun Gothic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>음성</td>\n",
       "      <td>15.12</td>\n",
       "      <td>16.68</td>\n",
       "      <td>98.78</td>\n",
       "      <td>716.6</td>\n",
       "      <td>0.08876</td>\n",
       "      <td>0.09588</td>\n",
       "      <td>0.07550</td>\n",
       "      <td>0.04079</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>...</td>\n",
       "      <td>17.77</td>\n",
       "      <td>20.24</td>\n",
       "      <td>117.70</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.33310</td>\n",
       "      <td>0.33270</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.09740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>양성</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.05736</td>\n",
       "      <td>0.02531</td>\n",
       "      <td>0.01698</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>...</td>\n",
       "      <td>11.60</td>\n",
       "      <td>12.02</td>\n",
       "      <td>73.66</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.14360</td>\n",
       "      <td>0.12570</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.04603</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.07699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>음성</td>\n",
       "      <td>18.31</td>\n",
       "      <td>18.58</td>\n",
       "      <td>118.60</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>0.08588</td>\n",
       "      <td>0.08468</td>\n",
       "      <td>0.08169</td>\n",
       "      <td>0.05814</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>...</td>\n",
       "      <td>21.31</td>\n",
       "      <td>26.36</td>\n",
       "      <td>139.20</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.24450</td>\n",
       "      <td>0.35380</td>\n",
       "      <td>0.15710</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.06938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>양성</td>\n",
       "      <td>14.92</td>\n",
       "      <td>14.93</td>\n",
       "      <td>96.45</td>\n",
       "      <td>686.9</td>\n",
       "      <td>0.08098</td>\n",
       "      <td>0.08549</td>\n",
       "      <td>0.05539</td>\n",
       "      <td>0.03221</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>...</td>\n",
       "      <td>17.18</td>\n",
       "      <td>18.22</td>\n",
       "      <td>112.00</td>\n",
       "      <td>906.6</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.27910</td>\n",
       "      <td>0.31510</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.08273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>양성</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>음성</td>\n",
       "      <td>19.55</td>\n",
       "      <td>23.21</td>\n",
       "      <td>128.90</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>0.10100</td>\n",
       "      <td>0.13180</td>\n",
       "      <td>0.18560</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>...</td>\n",
       "      <td>20.82</td>\n",
       "      <td>30.44</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>0.12510</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.38290</td>\n",
       "      <td>0.18250</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.07602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>음성</td>\n",
       "      <td>19.10</td>\n",
       "      <td>26.29</td>\n",
       "      <td>129.10</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>0.12150</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.14690</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>...</td>\n",
       "      <td>20.33</td>\n",
       "      <td>32.72</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>0.13920</td>\n",
       "      <td>0.28170</td>\n",
       "      <td>0.24320</td>\n",
       "      <td>0.18410</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.09203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>음성</td>\n",
       "      <td>24.25</td>\n",
       "      <td>20.20</td>\n",
       "      <td>166.20</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>0.14470</td>\n",
       "      <td>0.28670</td>\n",
       "      <td>0.42680</td>\n",
       "      <td>0.20120</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>...</td>\n",
       "      <td>26.02</td>\n",
       "      <td>23.99</td>\n",
       "      <td>180.90</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>0.16960</td>\n",
       "      <td>0.42440</td>\n",
       "      <td>0.58030</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.08009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>음성</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>양성</td>\n",
       "      <td>11.76</td>\n",
       "      <td>21.60</td>\n",
       "      <td>74.72</td>\n",
       "      <td>427.9</td>\n",
       "      <td>0.08637</td>\n",
       "      <td>0.04966</td>\n",
       "      <td>0.01657</td>\n",
       "      <td>0.01115</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>...</td>\n",
       "      <td>12.98</td>\n",
       "      <td>25.72</td>\n",
       "      <td>82.98</td>\n",
       "      <td>516.5</td>\n",
       "      <td>0.10850</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.05523</td>\n",
       "      <td>0.03715</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>0.06563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0          음성        15.12         16.68           98.78      716.6   \n",
       "1          양성        10.80          9.71           68.77      357.6   \n",
       "2          음성        18.31         18.58          118.60     1041.0   \n",
       "3          양성        14.92         14.93           96.45      686.9   \n",
       "4          양성        12.89         13.12           81.89      515.9   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "315        음성        19.55         23.21          128.90     1174.0   \n",
       "316        음성        19.10         26.29          129.10     1132.0   \n",
       "317        음성        24.25         20.20          166.20     1761.0   \n",
       "318        음성        19.17         24.80          132.40     1123.0   \n",
       "319        양성        11.76         21.60           74.72      427.9   \n",
       "\n",
       "     mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0            0.08876           0.09588         0.07550              0.04079   \n",
       "1            0.09594           0.05736         0.02531              0.01698   \n",
       "2            0.08588           0.08468         0.08169              0.05814   \n",
       "3            0.08098           0.08549         0.05539              0.03221   \n",
       "4            0.06955           0.03729         0.02260              0.01171   \n",
       "..               ...               ...             ...                  ...   \n",
       "315          0.10100           0.13180         0.18560              0.10210   \n",
       "316          0.12150           0.17910         0.19370              0.14690   \n",
       "317          0.14470           0.28670         0.42680              0.20120   \n",
       "318          0.09740           0.24580         0.20650              0.11180   \n",
       "319          0.08637           0.04966         0.01657              0.01115   \n",
       "\n",
       "     mean_symmetry  ...  worst_radius  worst_texture  worst_perimeter  \\\n",
       "0           0.1594  ...         17.77          20.24           117.70   \n",
       "1           0.1381  ...         11.60          12.02            73.66   \n",
       "2           0.1621  ...         21.31          26.36           139.20   \n",
       "3           0.1687  ...         17.18          18.22           112.00   \n",
       "4           0.1337  ...         13.62          15.54            87.40   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "315         0.1989  ...         20.82          30.44           142.00   \n",
       "316         0.1634  ...         20.33          32.72           141.30   \n",
       "317         0.2655  ...         26.02          23.99           180.90   \n",
       "318         0.2397  ...         20.96          29.94           151.70   \n",
       "319         0.1495  ...         12.98          25.72            82.98   \n",
       "\n",
       "     worst_area  worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "0         989.5           0.14910            0.33310          0.33270   \n",
       "1         414.0           0.14360            0.12570          0.10470   \n",
       "2        1410.0           0.12340            0.24450          0.35380   \n",
       "3         906.6           0.10650            0.27910          0.31510   \n",
       "4         577.0           0.09616            0.11470          0.11860   \n",
       "..          ...               ...                ...              ...   \n",
       "315      1313.0           0.12510            0.24140          0.38290   \n",
       "316      1298.0           0.13920            0.28170          0.24320   \n",
       "317      2073.0           0.16960            0.42440          0.58030   \n",
       "318      1332.0           0.10370            0.39030          0.36390   \n",
       "319       516.5           0.10850            0.08615          0.05523   \n",
       "\n",
       "     worst_concave_points  worst_symmetry  worst_fractal_dimension  \n",
       "0                 0.12520          0.3415                  0.09740  \n",
       "1                 0.04603          0.2090                  0.07699  \n",
       "2                 0.15710          0.3206                  0.06938  \n",
       "3                 0.11470          0.2688                  0.08273  \n",
       "4                 0.05366          0.2309                  0.06915  \n",
       "..                    ...             ...                      ...  \n",
       "315               0.18250          0.2576                  0.07602  \n",
       "316               0.18410          0.2311                  0.09203  \n",
       "317               0.22480          0.3222                  0.08009  \n",
       "318               0.17670          0.3176                  0.10230  \n",
       "319               0.03715          0.2433                  0.06563  \n",
       "\n",
       "[320 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"C:/Users/Myung-jin/21aibigdata/bigdata/유방암.CSV\" , encoding = \"euc-kr\")\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 유방암.csv 데이터는 변수 31개, 자료 수가 320개로 이루어져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "mean_radius                0\n",
       "mean_texture               0\n",
       "mean_perimeter             0\n",
       "mean_area                  0\n",
       "mean_smoothness            0\n",
       "mean_compactness           0\n",
       "mean_concavity             0\n",
       "mean_concave_points        0\n",
       "mean_symmetry              0\n",
       "mean_fractal_dimension     0\n",
       "radius_error               0\n",
       "texture_error              0\n",
       "perimeter_error            0\n",
       "area_error                 0\n",
       "smoothness_error           0\n",
       "compactness_error          0\n",
       "concavity_error            0\n",
       "concave_points_error       0\n",
       "symmetry_error             0\n",
       "fractal_dimension_error    0\n",
       "worst_radius               0\n",
       "worst_texture              0\n",
       "worst_perimeter            0\n",
       "worst_area                 0\n",
       "worst_smoothness           0\n",
       "worst_compactness          0\n",
       "worst_concavity            0\n",
       "worst_concave_points       0\n",
       "worst_symmetry             0\n",
       "worst_fractal_dimension    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 320 entries, 0 to 319\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                320 non-null    object \n",
      " 1   mean_radius              320 non-null    float64\n",
      " 2   mean_texture             320 non-null    float64\n",
      " 3   mean_perimeter           320 non-null    float64\n",
      " 4   mean_area                320 non-null    float64\n",
      " 5   mean_smoothness          320 non-null    float64\n",
      " 6   mean_compactness         320 non-null    float64\n",
      " 7   mean_concavity           320 non-null    float64\n",
      " 8   mean_concave_points      320 non-null    float64\n",
      " 9   mean_symmetry            320 non-null    float64\n",
      " 10  mean_fractal_dimension   320 non-null    float64\n",
      " 11  radius_error             320 non-null    float64\n",
      " 12  texture_error            320 non-null    float64\n",
      " 13  perimeter_error          320 non-null    float64\n",
      " 14  area_error               320 non-null    float64\n",
      " 15  smoothness_error         320 non-null    float64\n",
      " 16  compactness_error        320 non-null    float64\n",
      " 17  concavity_error          320 non-null    float64\n",
      " 18  concave_points_error     320 non-null    float64\n",
      " 19  symmetry_error           320 non-null    float64\n",
      " 20  fractal_dimension_error  320 non-null    float64\n",
      " 21  worst_radius             320 non-null    float64\n",
      " 22  worst_texture            320 non-null    float64\n",
      " 23  worst_perimeter          320 non-null    float64\n",
      " 24  worst_area               320 non-null    float64\n",
      " 25  worst_smoothness         320 non-null    float64\n",
      " 26  worst_compactness        320 non-null    float64\n",
      " 27  worst_concavity          320 non-null    float64\n",
      " 28  worst_concave_points     320 non-null    float64\n",
      " 29  worst_symmetry           320 non-null    float64\n",
      " 30  worst_fractal_dimension  320 non-null    float64\n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 77.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 각 변수의 데이터 타입을 확인해보니 목표변수인 진단결과(diagnosis)가 이산형 변수임을 알 수 있다. 목표변수가 이산형이기 때문에 분류를 할 때 비선형 분류를 해야 한다. 비선형 서포트 벡터 머신 기법을 통해 분류를 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 목표변수 변환 및 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.12</td>\n",
       "      <td>16.68</td>\n",
       "      <td>98.78</td>\n",
       "      <td>716.6</td>\n",
       "      <td>0.08876</td>\n",
       "      <td>0.09588</td>\n",
       "      <td>0.07550</td>\n",
       "      <td>0.04079</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>...</td>\n",
       "      <td>17.77</td>\n",
       "      <td>20.24</td>\n",
       "      <td>117.70</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.3327</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.09740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.05736</td>\n",
       "      <td>0.02531</td>\n",
       "      <td>0.01698</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>...</td>\n",
       "      <td>11.60</td>\n",
       "      <td>12.02</td>\n",
       "      <td>73.66</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.14360</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.04603</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.07699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>18.31</td>\n",
       "      <td>18.58</td>\n",
       "      <td>118.60</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>0.08588</td>\n",
       "      <td>0.08468</td>\n",
       "      <td>0.08169</td>\n",
       "      <td>0.05814</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>...</td>\n",
       "      <td>21.31</td>\n",
       "      <td>26.36</td>\n",
       "      <td>139.20</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.2445</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.15710</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.06938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.92</td>\n",
       "      <td>14.93</td>\n",
       "      <td>96.45</td>\n",
       "      <td>686.9</td>\n",
       "      <td>0.08098</td>\n",
       "      <td>0.08549</td>\n",
       "      <td>0.05539</td>\n",
       "      <td>0.03221</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>...</td>\n",
       "      <td>17.18</td>\n",
       "      <td>18.22</td>\n",
       "      <td>112.00</td>\n",
       "      <td>906.6</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.08273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0          0        15.12         16.68           98.78      716.6   \n",
       "1          1        10.80          9.71           68.77      357.6   \n",
       "2          0        18.31         18.58          118.60     1041.0   \n",
       "3          1        14.92         14.93           96.45      686.9   \n",
       "4          1        12.89         13.12           81.89      515.9   \n",
       "\n",
       "   mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0          0.08876           0.09588         0.07550              0.04079   \n",
       "1          0.09594           0.05736         0.02531              0.01698   \n",
       "2          0.08588           0.08468         0.08169              0.05814   \n",
       "3          0.08098           0.08549         0.05539              0.03221   \n",
       "4          0.06955           0.03729         0.02260              0.01171   \n",
       "\n",
       "   mean_symmetry  ...  worst_radius  worst_texture  worst_perimeter  \\\n",
       "0         0.1594  ...         17.77          20.24           117.70   \n",
       "1         0.1381  ...         11.60          12.02            73.66   \n",
       "2         0.1621  ...         21.31          26.36           139.20   \n",
       "3         0.1687  ...         17.18          18.22           112.00   \n",
       "4         0.1337  ...         13.62          15.54            87.40   \n",
       "\n",
       "   worst_area  worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "0       989.5           0.14910             0.3331           0.3327   \n",
       "1       414.0           0.14360             0.1257           0.1047   \n",
       "2      1410.0           0.12340             0.2445           0.3538   \n",
       "3       906.6           0.10650             0.2791           0.3151   \n",
       "4       577.0           0.09616             0.1147           0.1186   \n",
       "\n",
       "   worst_concave_points  worst_symmetry  worst_fractal_dimension  \n",
       "0               0.12520          0.3415                  0.09740  \n",
       "1               0.04603          0.2090                  0.07699  \n",
       "2               0.15710          0.3206                  0.06938  \n",
       "3               0.11470          0.2688                  0.08273  \n",
       "4               0.05366          0.2309                  0.06915  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[\"diagnosis\"] = np.where(df_raw[\"diagnosis\"] == \"양성\", 1, 0)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 진단결과가 양성 혹은 음성으로 나뉘어지기 때문에 이 범주를 좀 더 쉽게 표현하고자 0, 1의 숫자로 표현을 변경했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.12</td>\n",
       "      <td>16.68</td>\n",
       "      <td>98.78</td>\n",
       "      <td>716.6</td>\n",
       "      <td>0.08876</td>\n",
       "      <td>0.09588</td>\n",
       "      <td>0.07550</td>\n",
       "      <td>0.04079</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.05986</td>\n",
       "      <td>...</td>\n",
       "      <td>17.77</td>\n",
       "      <td>20.24</td>\n",
       "      <td>117.70</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.3327</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.09740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.80</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.05736</td>\n",
       "      <td>0.02531</td>\n",
       "      <td>0.01698</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>...</td>\n",
       "      <td>11.60</td>\n",
       "      <td>12.02</td>\n",
       "      <td>73.66</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.14360</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.04603</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.07699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.31</td>\n",
       "      <td>18.58</td>\n",
       "      <td>118.60</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>0.08588</td>\n",
       "      <td>0.08468</td>\n",
       "      <td>0.08169</td>\n",
       "      <td>0.05814</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.05425</td>\n",
       "      <td>...</td>\n",
       "      <td>21.31</td>\n",
       "      <td>26.36</td>\n",
       "      <td>139.20</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.2445</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.15710</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.06938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.92</td>\n",
       "      <td>14.93</td>\n",
       "      <td>96.45</td>\n",
       "      <td>686.9</td>\n",
       "      <td>0.08098</td>\n",
       "      <td>0.08549</td>\n",
       "      <td>0.05539</td>\n",
       "      <td>0.03221</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.05669</td>\n",
       "      <td>...</td>\n",
       "      <td>17.18</td>\n",
       "      <td>18.22</td>\n",
       "      <td>112.00</td>\n",
       "      <td>906.6</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.08273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        15.12         16.68           98.78      716.6          0.08876   \n",
       "1        10.80          9.71           68.77      357.6          0.09594   \n",
       "2        18.31         18.58          118.60     1041.0          0.08588   \n",
       "3        14.92         14.93           96.45      686.9          0.08098   \n",
       "4        12.89         13.12           81.89      515.9          0.06955   \n",
       "\n",
       "   mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "0           0.09588         0.07550              0.04079         0.1594   \n",
       "1           0.05736         0.02531              0.01698         0.1381   \n",
       "2           0.08468         0.08169              0.05814         0.1621   \n",
       "3           0.08549         0.05539              0.03221         0.1687   \n",
       "4           0.03729         0.02260              0.01171         0.1337   \n",
       "\n",
       "   mean_fractal_dimension  ...  worst_radius  worst_texture  worst_perimeter  \\\n",
       "0                 0.05986  ...         17.77          20.24           117.70   \n",
       "1                 0.06400  ...         11.60          12.02            73.66   \n",
       "2                 0.05425  ...         21.31          26.36           139.20   \n",
       "3                 0.05669  ...         17.18          18.22           112.00   \n",
       "4                 0.05581  ...         13.62          15.54            87.40   \n",
       "\n",
       "   worst_area  worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "0       989.5           0.14910             0.3331           0.3327   \n",
       "1       414.0           0.14360             0.1257           0.1047   \n",
       "2      1410.0           0.12340             0.2445           0.3538   \n",
       "3       906.6           0.10650             0.2791           0.3151   \n",
       "4       577.0           0.09616             0.1147           0.1186   \n",
       "\n",
       "   worst_concave_points  worst_symmetry  worst_fractal_dimension  \n",
       "0               0.12520          0.3415                  0.09740  \n",
       "1               0.04603          0.2090                  0.07699  \n",
       "2               0.15710          0.3206                  0.06938  \n",
       "3               0.11470          0.2688                  0.08273  \n",
       "4               0.05366          0.2309                  0.06915  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_x = df_raw.drop(\"diagnosis\", axis = 1, inplace = False)\n",
    "df_raw_y = df_raw[\"diagnosis\"]\n",
    "df_raw_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: diagnosis, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - train, test 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data X size : (192, 30)\n",
      "train data Y size : (192,)\n",
      "test data X size : (128, 30)\n",
      "test data Y size : (128,)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split(X: 설명변수 데이터, Y: 목표변수 데이터, test_size = test 데이터 비율, random_state: 랜덤)\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(df_raw_x, # 설명변수 데이터\n",
    "                                                                df_raw_y, # 목표변수 데이터\n",
    "                                                                test_size = 0.4, # test 데이터의 비율\n",
    "                                                                random_state = 1234)  # random state\n",
    "\n",
    "print(\"train data X size : {}\".format(df_train_x.shape))\n",
    "print(\"train data Y size : {}\".format(df_train_y.shape))\n",
    "print(\"test data X size : {}\".format(df_test_x.shape))\n",
    "print(\"test data Y size : {}\".format(df_test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 default parameter로 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1 default parameter로 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accucary on training set: 0.885\n",
      "Accucary on test set: 0.891\n"
     ]
    }
   ],
   "source": [
    "svm_uncustomized = SVC(random_state = 1234)\n",
    "svm_uncustomized.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 훈련 데이터 정확도\n",
    "print(\"Accucary on training set: {:.3f}\".format(svm_uncustomized.score(df_train_x, df_train_y)))\n",
    "\n",
    "# test 데이터 정확도\n",
    "print(\"Accucary on test set: {:.3f}\".format(svm_uncustomized.score(df_test_x, df_test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=1234)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_uncustomized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 기본 파라미터로 SVM 모델을 생성하였더니 train 데이터의 정확도가 88.5%, test 데이터의 정확도가 89.1%가 나왔다. 훈련 데이터와 테스트 데이터의 성능 차가 크지 않지만 둘 다 낮은 정확도(낮은 성능을 내는)가 나기 때문에 **과소적합(underfitting)이라는 것을 확인**할 수 있다. 훈련 데이터에서도 좀 더 잘 학습하면서 성능을 향상시켜보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2 데이터 스케일링 후 default parameter로 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 커널 기법을 사용하는 SVM 분류 모형은 scale에 민감하기 때문에 정규화가 필요하다. 이론적으로 스케일링을 하면 좋은 것을 알고 있지만, 이를 실제로 비교 후 확인해보기 위해 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.157678</td>\n",
       "      <td>-0.879112</td>\n",
       "      <td>-0.165550</td>\n",
       "      <td>-0.232872</td>\n",
       "      <td>-0.744948</td>\n",
       "      <td>-0.479220</td>\n",
       "      <td>-0.550769</td>\n",
       "      <td>-0.628488</td>\n",
       "      <td>-0.997431</td>\n",
       "      <td>-0.392627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149283</td>\n",
       "      <td>-1.156442</td>\n",
       "      <td>-0.153789</td>\n",
       "      <td>-0.224951</td>\n",
       "      <td>0.490637</td>\n",
       "      <td>0.139396</td>\n",
       "      <td>-0.094470</td>\n",
       "      <td>-0.301949</td>\n",
       "      <td>0.525611</td>\n",
       "      <td>0.511081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.312779</td>\n",
       "      <td>-2.560965</td>\n",
       "      <td>-1.328928</td>\n",
       "      <td>-1.150194</td>\n",
       "      <td>-0.240274</td>\n",
       "      <td>-1.153621</td>\n",
       "      <td>-1.143404</td>\n",
       "      <td>-1.199934</td>\n",
       "      <td>-1.773612</td>\n",
       "      <td>0.184077</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.341759</td>\n",
       "      <td>-2.517236</td>\n",
       "      <td>-1.380396</td>\n",
       "      <td>-1.124201</td>\n",
       "      <td>0.254373</td>\n",
       "      <td>-1.046076</td>\n",
       "      <td>-1.159323</td>\n",
       "      <td>-1.480312</td>\n",
       "      <td>-1.387506</td>\n",
       "      <td>-0.507149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.695279</td>\n",
       "      <td>-0.420644</td>\n",
       "      <td>0.602798</td>\n",
       "      <td>0.596040</td>\n",
       "      <td>-0.947380</td>\n",
       "      <td>-0.675307</td>\n",
       "      <td>-0.477679</td>\n",
       "      <td>-0.212084</td>\n",
       "      <td>-0.899042</td>\n",
       "      <td>-1.174101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534893</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>0.445031</td>\n",
       "      <td>0.432104</td>\n",
       "      <td>-0.613360</td>\n",
       "      <td>-0.367031</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.172850</td>\n",
       "      <td>0.223844</td>\n",
       "      <td>-0.886803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.211154</td>\n",
       "      <td>-1.301385</td>\n",
       "      <td>-0.255876</td>\n",
       "      <td>-0.308762</td>\n",
       "      <td>-1.291796</td>\n",
       "      <td>-0.661126</td>\n",
       "      <td>-0.788224</td>\n",
       "      <td>-0.834410</td>\n",
       "      <td>-0.658535</td>\n",
       "      <td>-0.834209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263312</td>\n",
       "      <td>-1.490846</td>\n",
       "      <td>-0.312546</td>\n",
       "      <td>-0.354487</td>\n",
       "      <td>-1.339335</td>\n",
       "      <td>-0.169261</td>\n",
       "      <td>-0.176669</td>\n",
       "      <td>-0.458230</td>\n",
       "      <td>-0.524077</td>\n",
       "      <td>-0.220788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.753945</td>\n",
       "      <td>-1.738136</td>\n",
       "      <td>-0.820314</td>\n",
       "      <td>-0.745704</td>\n",
       "      <td>-2.095198</td>\n",
       "      <td>-1.505004</td>\n",
       "      <td>-1.175403</td>\n",
       "      <td>-1.326415</td>\n",
       "      <td>-1.933950</td>\n",
       "      <td>-0.956793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.951354</td>\n",
       "      <td>-1.934512</td>\n",
       "      <td>-0.997708</td>\n",
       "      <td>-0.869505</td>\n",
       "      <td>-1.783511</td>\n",
       "      <td>-1.108951</td>\n",
       "      <td>-1.094404</td>\n",
       "      <td>-1.366747</td>\n",
       "      <td>-1.071301</td>\n",
       "      <td>-0.898278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0    -0.157678     -0.879112       -0.165550  -0.232872        -0.744948   \n",
       "1    -1.312779     -2.560965       -1.328928  -1.150194        -0.240274   \n",
       "2     0.695279     -0.420644        0.602798   0.596040        -0.947380   \n",
       "3    -0.211154     -1.301385       -0.255876  -0.308762        -1.291796   \n",
       "4    -0.753945     -1.738136       -0.820314  -0.745704        -2.095198   \n",
       "\n",
       "   mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "0         -0.479220       -0.550769            -0.628488      -0.997431   \n",
       "1         -1.153621       -1.143404            -1.199934      -1.773612   \n",
       "2         -0.675307       -0.477679            -0.212084      -0.899042   \n",
       "3         -0.661126       -0.788224            -0.834410      -0.658535   \n",
       "4         -1.505004       -1.175403            -1.326415      -1.933950   \n",
       "\n",
       "   mean_fractal_dimension  ...  worst_radius  worst_texture  worst_perimeter  \\\n",
       "0               -0.392627  ...     -0.149283      -1.156442        -0.153789   \n",
       "1                0.184077  ...     -1.341759      -2.517236        -1.380396   \n",
       "2               -1.174101  ...      0.534893      -0.143296         0.445031   \n",
       "3               -0.834209  ...     -0.263312      -1.490846        -0.312546   \n",
       "4               -0.956793  ...     -0.951354      -1.934512        -0.997708   \n",
       "\n",
       "   worst_area  worst_smoothness  worst_compactness  worst_concavity  \\\n",
       "0   -0.224951          0.490637           0.139396        -0.094470   \n",
       "1   -1.124201          0.254373          -1.046076        -1.159323   \n",
       "2    0.432104         -0.613360          -0.367031         0.004076   \n",
       "3   -0.354487         -1.339335          -0.169261        -0.176669   \n",
       "4   -0.869505         -1.783511          -1.108951        -1.094404   \n",
       "\n",
       "   worst_concave_points  worst_symmetry  worst_fractal_dimension  \n",
       "0             -0.301949        0.525611                 0.511081  \n",
       "1             -1.480312       -1.387506                -0.507149  \n",
       "2              0.172850        0.223844                -0.886803  \n",
       "3             -0.458230       -0.524077                -0.220788  \n",
       "4             -1.366747       -1.071301                -0.898278  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_feature_name = df_train_x.columns\n",
    "\n",
    "#표준정규분포로 스케일 조정\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_raw_x)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=v_feature_name)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data X size : (192, 30)\n",
      "test data X size : (128, 30)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "df_scaled_train_x, df_scaled_test_x = train_test_split(df_scaled, # 설명변수 데이터\n",
    "                                                                test_size = 0.4, # test 데이터의 비율\n",
    "                                                                random_state = 1234)  # random state\n",
    "\n",
    "print(\"train data X size : {}\".format(df_scaled_train_x.shape))\n",
    "print(\"test data X size : {}\".format(df_scaled_test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accucary on training set: 0.995\n",
      "Accucary on test set: 0.961\n"
     ]
    }
   ],
   "source": [
    "svm_scaled = SVC(random_state = 1234)\n",
    "svm_scaled.fit(df_scaled_train_x, df_train_y)\n",
    "\n",
    "# 훈련 데이터 정확도\n",
    "print(\"Accucary on training set: {:.3f}\".format(svm_scaled.score(df_scaled_train_x, df_train_y)))\n",
    "\n",
    "# test 데이터 정확도\n",
    "print(\"Accucary on test set: {:.3f}\".format(svm_scaled.score(df_scaled_test_x, df_test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 설명변수에 대해 스케일링을 진행한 후 이 데이터를 토대로 SVM 모델을 생성하여 훈련 데이터와 테스트 데이터의 정확도를 측정해보았다.   \n",
    "  \n",
    "> 스케일링 전 -> 후  \n",
    "train 데이터의 정확도 : 88.5% -> 99.5%   \n",
    "test 데이터의 정확도가 89.1% -> 96.1%  \n",
    "  \n",
    "> 스케일링을 통해 훈련 데이터와 테스트 데이터의 성능이 향상되었고, 과소적합을 면하였다. 하지만 스케일링을 하니 훈련 데이터에 대해 **과대적합(overfitting)이 일어나는 것**을 알 수 있다. 이제 SVC의 파라미터 C와 gamma 값을 바꿔가며 모델에 적용해보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. scale 조정 후 SVC 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - parameter 변경 : c(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  TrainAccuracy  TestAccuracy\n",
       "0   0.01          0.599         0.758\n",
       "1   0.10          0.964         0.906\n",
       "2   1.00          0.995         0.961\n",
       "3  10.00          1.000         0.961"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "\n",
    "para_c = [10**c for c in range(-2, 2)]\n",
    "\n",
    "for v_C in para_c:\n",
    "    svm = SVC(C = v_C, random_state = 1234)\n",
    "    svm.fit(df_scaled_train_x, df_train_y)\n",
    "    train_accuracy.append(svm.score(df_scaled_train_x, df_train_y))\n",
    "    test_accuracy.append(svm.score(df_scaled_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_c = pd.DataFrame()\n",
    "df_accuracy_c[\"C\"] = para_c\n",
    "df_accuracy_c[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_c[\"TestAccuracy\"] = test_accuracy\n",
    "df_accuracy_c.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xdc2aea8970>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도를 그래프로 표현\n",
    "plt.plot(para_c, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_c, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"C\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c를 (0.01, 0.1, 1, 10)으로 설정했을 때 C가 1 초과일 때 train 데이터에서 과적합이 일어나고 test 데이터의 정확도의 변동이 없다. 그래서 c의 범위를 0.1 ~ 1.0으로 변경을 하였더니 C=1일 때 모델의 정확성이 가장 높고 성능차가 적음을 알 수 있다. 그래서 **C=1을 선택**하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - parameter 변경 : Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>TrainAccuracy</th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gamma  TrainAccuracy  TestAccuracy\n",
       "0   0.001          0.984         0.930\n",
       "1   0.010          0.995         0.938\n",
       "2   0.100          1.000         0.922\n",
       "3   1.000          1.000         0.773\n",
       "4  10.000          1.000         0.766"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "\n",
    "para_gamma = [10**gamma for gamma in range(-3, 2)]\n",
    "\n",
    "for v_gamma in para_gamma:\n",
    "    svm = SVC(gamma = v_gamma, C=1, random_state = 1234)\n",
    "    svm.fit(df_scaled_train_x, df_train_y)\n",
    "    train_accuracy.append(svm.score(df_scaled_train_x, df_train_y))\n",
    "    test_accuracy.append(svm.score(df_scaled_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_gamma = pd.DataFrame()\n",
    "df_accuracy_gamma[\"gamma\"] = para_gamma\n",
    "df_accuracy_gamma[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_gamma[\"TestAccuracy\"] = test_accuracy\n",
    "df_accuracy_gamma.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xdc2af16bb0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEECAYAAADK0VhyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkj0lEQVR4nO3deXgV5d3/8fc3ZGNJSIRAhbCqqKiIEARRJIgLVrS2haJt3XChSNXqjyqtSwWsS61Pfaq1ili1Lli1FqsgUtEA4oLgg0pZKhRBRAGj7BCy3L8/ZhJOVk6SM5kk5/O6rlznZO45M98T9HzOfc/MPeacQ0RE4ltC2AWIiEj4FAYiIqIwEBERhYGIiKAwEBERIDHsAuqqffv2rnv37mGXISLSpCxduvRr51xWxeVNNgy6d+/OkiVLwi5DRKRJMbP1VS3XMJGIiCgMREREYSAiIigMREQEhYGIiKAwEBERAgoDM8sys9+a2dQKy9uY2QwzW2BmM80s3V9+vpktNLP3zWxMEDWJiEj1grrO4D5gDdCqwvLrgVecc8+a2QRgvJk9CEwEhvv1vG1mLzvn9gVUW5n1+bt56cMv0DTeItKUfL9fNj3at47pNgMJA+fcxWaWC4yo0HQacLf//O/Aw8ASYJ5zrgAoMLP3gaOAZRW3a2ZXAVcBdO3atV41FhQVM/aJD1i7dTdm9dqUiEiD6tcts2mEQQ1SnHOF/vN8IBPoAGyNWKd0eSXOuWnANICcnJx6fZ1/ZP5/Wbt1N09cNoDcIzvUZ1MiIk1eQx9ALjGz0n1m4oXAdsp/+JcuD8x/t+7iwbfWMLLPoQoCEREaPgzeB77nP/8h8AawGBhhZklm1go4FlgVVAHOOW6ZuZyUxARuG9k7qN2IiDQpDRIGZnaPmSUDdwFXmVke0B943Dn3NfAE8DYwG/iNc64oqFreX/cN76zN58azjqRDempQuxERaVICO2bgnMsD8vznN/mLvwbOrmLdR4FHg6ol0tadBQCcdFi7htidiEiTEHcXnRUUlQCQ3KJFyJWIiDQecRgGxQCkJMXdWxcRqVbcfSLu93sGKYlx99ZFRKoVd5+IBWVhoGEiEZFS8RcGhf4xA/UMRETKxN0nYkFRMUktjBYJmoNCRKRUHIZBiYaIREQqiMMwKNbBYxGRChp6orrQXXvaEVxyUvewyxARaVTiLgw6pKdqGgoRkQo0XiIiIgoDERFRGIiICAoDERFBYSAiIigMREQEhYGIiKAwEBERFAYiIoLCQEREUBiIiAgKAxERQWEgIiIoDEREBIWBiIigMBARERQGIiKCwkBERFAYiIgICgMREUFhICIiKAxERASFgYiIoDAQERECDAMzm2pm881skZkdE7E8w8xe9NteNbNMf/ljZvaOmeWZ2e+CqktERCoLJAzMbAjQ0Tk3FBgH3BvRPAl41m+bCVzvL88AznbO5TrnbgyiLhERqVpQPYMzgRkAzrnlwCERbccBb/nPXwEG+M/TgB01bdTMrjKzJWa2ZOvWrbGtWEQkjgUVBh2AyE/rIjMr3dfHwA/858OBRP+5A/LMbK7fs6jEOTfNOZfjnMvJysoKom4RkbiUePBV6mQ7kBnxe4lzrsR/fifwgJldAOQBnwE4584CMLMuwCygT0C1iYhIBUH1DBYCowDMrDewsbTBObfTOXepc+4MIB14yl+vNJi+BQoDqktERKoQVM9gFvBdM1sI7ATGmdk9wK3AKcAdgAEvOecW+K+Z4wdCC+DXAdUlIiJVCCQM/CGh8RUW3+Q/vgkMruI1pwdRi4iIHJwuOhMREYWBiIgoDEREBIWBiIigMBAREeIxDEqKwbmwqxARaVTiLww+mgGTM2DWxLArERFpNOIvDAr3eo/rF4Vbh4hIIxJ/YbB/t/e4dTWUlNS8rohInIi/MCjtGbhi+GZtuLWIiDQScRgGuw88/+LD8OoQEWlEgpqorvHqOhisBXy+GBKTw65GRKRRiL8wOOq73o+IiJSJv2GiSMVFOogsIkI8h8HaN+HuLrD5k7ArEREJXfyGQWZ3KNyjg8giIsR1GPSAlpmwSWEgIhK/YWAGnfqpZyAiQjyHAUDn/rBlxYGrkkVE4lT8nVoa6cgR0CIJivcDrcOuRkQkNPEdBp37ez8iInEuvoeJAPZthy8/DrsKEZFQKQxm3wjPjNINb0QkrikMsnNg12bY/nnYlYiIhEZhkD3Ae9z4Qbh1iIiESGHQ8RhIbAkbl4RdiYhIaBQGLZKg0wnqGYhIXIvvU0tLnTEZklqGXYWISGgUBgBdTgy7AhGRUGmYCLx7Gnz8AqxbGHYlIiKhUBgAJCTAG7fD0sfDrkREJBQKg1LZOfC5DiKLSHxSGJTKHgDbN8DOr8KuRESkwUUVBmbW/EOj7OIzXW8gIvEn2g/5BWb2KzNrF+2GzWyqmc03s0VmdkzE8gwze9Fve9XMMv3l55vZQjN738zG1PJ91N+hfSAhCTb/u8F3LSIStmjDYAjwMfCwmT1qZn1rWtnMhgAdnXNDgXHAvRHNk4Bn/baZwPVm1hqYCJwOnAZMMrPU2ryRektqCTesgKE3NuhuRUQag6iuM3DOOWCWmX0K3AY8YmbfAjc451ZU8ZIzgRn+a5eb2SERbccB9/jPXwGeAAYB85xzBUCBmb0PHAUsq/U7qo82HRp0dyLNRWFhIRs3bmTfvn1hlyK+1NRUsrOzSUpKimr9qMLAzC4BLgTWAXc55/5tZt2A54CTqnhJB2BrxO9FZpbgnCvB62H8AHgMGO7XUHH9fCCzijquAq4C6Nq1azSl187Xn0LeXXDqL6HD0bHfvkgztXHjRtLS0ujevTtmFnY5cc85R35+Phs3bqRHjx5RvSbaYaIs4ALn3Hjn3L/9na0HHq5m/e2U/zAv8YMA4E5giJn9C+gBfFbF+pmUDwf8fU5zzuU453KysrKiLL0WEhJh+d9h/Tux37ZIM7Zv3z7atWunIGgkzIx27drVqqcWbRj0cc5t83eSaGYPAjjnnqxm/YXAKH/93sDG0gbn3E7n3KXOuTOAdOApYDEwwsySzKwVcCywKup3ESuZ3aFVe51RJFIHCoLGpbb/HtGGQXbpE+dcEdD7IOvPApLNbCHwe+AmM7vHzJLN7DQze8fM3gW+ds4tcM59jXfs4G1gNvAbfz8Ny8w7xVQzmIo0KVdccQW5ublkZGRw6qmnkpuby9atlQYXKpk4cWKt9/Xhhx+SkZHBzp0761Jqo2Uuits9mtkrwK+dc5+Y2WHAX/yzgUKTk5PjliwJ4Bv8gt/Dm1PhxnXQ6pCDry8irFy5kqOPDv84W25uLnPmzCE19cDJiM65mPZaxo8fT3p6Oj169OBnP/tZzLYLsa+1qn8XM1vqnMupuG60s5ZeAzxkZhlAsf9789RlIHQ8zrsVpsJApNYmv/JvVmzaEdNt9u6Uzm/OPebgK0bIzc1lxIgRLFiwgNmzZ3PBBRewefNm9u7dy7PPPkvPnj0ZNGgQ7733Hk888QSLFy/m888/Z+3atUyZMoVRo0ZV2uaePXtYv349L7zwAuecc05ZGOzdu5drrrmGtWvXUlBQwJw5c8jPz+eaa65h165dZGdn8/TTT5ftD2DSpEmMGDGC3NxcBg4cyLHHHkvHjh258sorufrqq9mzZw9paWn84x//ICkpifvvv58XX3wRgJtvvpnbbruNxYsXY2ZMnz6doqKieoVTtKeWfgZ8t857aUp6DIHxb4ddhYjEQL9+/Zg0aRIADzzwAFlZWTz55JPMmDGDm2++udy627Zt45VXXmHLli2ce+65VYbB888/z+jRo2ndujW9evVi6dKl9O/fn3vvvZf+/fszffp0SkdbxowZw1133UXfvn0pKSmptK1Iq1at4tVXXyUrK4sdO3bw8ssvk5yczNixY1m8eDHFxcUsXryYBQsWkJCQQElJCfPnz+fNN99k+PDh/O1vf2PmzJn1+ltFe2rpOcB1QJvSZc65wfXac2PnnHcMQURqpbbf4IM0eLD3MbVlyxamTJlCmzZt2LRpE506daq07pAhQwDo0KH6642eeuopUlJSePnll9m2bRvTpk3jkUceYfHixfz1r38FDhy43bZtG3379gUgIaHmw7NHHHEEpWdIrlq1iieffJK0tDTWrVvHzp07Wb58OaNGjSrbTkJCAhMmTODmm28mIyODPn360Lp161r8ZSqL9gDyZOAKYB7wc7wrh5uvd/8E9/fx7nMgIk1WYqL3ffepp57i5JNP5u677+b444+vct3Isfqqxu1XrlxJ165dmT17NjNnziQvL49PPvmEXbt20atXL+bMmQNASUkJJSUlJCQksGbNGsC7KC/yEShri6wTYOrUqdxyyy3cfffdpKWlAdCrVy9ef/31snUKCwvp0qULJSUl3HvvvUyYMKF2f5gqRBsG251zG4BE59yHwFn13nNjltrWm8E0f83B1xWRRu/000/nzjvvZOTIkXz55Zd12sajjz7K6NGjyy07//zzmTFjBrfccgvPP/88p556KmeffTZ79uzhwQcfZOzYseTm5nLdddcBMHbsWC655BKmTJnC7t27q9zP6NGjGT58OKNGjaJt27YAnHfeeaSnpzNo0CBOP/10li5dCsCFF17Inj176NmzZ53eU6RozyaaBDwKXA+0B45yzuXWe+/1ENjZRABbV8OfToTvPQQn/CSYfYg0I43lbKJ4M378eH70ox8xbNiwKttrczZRtD2DZ5xz+cCtwDSa+8HkdkdASltdbyAijdbgwYNJSUmpNghqK9pTS58GhvoT1n0Ykz03ZgkJkN1fVyKLSKP1zjuxnTYn2jB4z8zuAN4BigCcc3NjWklj02cMfLNOZxWJSFyINgz2+I/+7cBwQPMOg+MvCLsCEZEGE+1FZ5ODLqRRKtgF+7ZB2+yDrioi0pRFe9HZW3i9gTLOudMCqagxeXSYdzD5wmfDrkREJFDRnk00Ajjb/7kWeL3m1ZuJzv29M4qiOP1WRMJT11lLAfLy8mpsv++++zjttOb/3TeqMHDOFUT8LAdaBlxX45CdA7u3wLYNYVciIjWYPn06eXl59O3bl7lz55KXl0e0N8AqnbuoOq+99hqdO3dm1aqGv8VKQ4oqDMzszIify4ATAq6rccj2j5fregOR2nn8nMo/ix/12vbvqbr9/57x2nfnV26rg2nTpjFkyBBOPvlkXnvtNQAmT57M4MGDGTRoEBs2bGD06NGsWLGC3Nxcvvnmm0rbePvttxk4cCBXXnkl06ZNK1u+bt06Ro4cSW5uLj/96U8BmDdvHkOHDmXo0KHcd9995OXllQuaQYMGAV5P5LLLLuOss87ihRdeYPbs2QwfPpyBAwdy2223Ad4sqFdccQXDhg1j8ODBzJ8/n0svvbRsWxdddBErV66s09+lOtGeTVR6n2OHd3/isTGtorHqcAwktvSuNziu8gyGItI4rV69mrlz57JgwQIKCws588wzOfvss3nppZdYtmwZZoZzjhdeeIFBgwZVO1T02GOPceutt9KzZ09+9atfUVBQQEpKCldffXW5GUl37tzJr3/9a+bOnUvbtm0pKSlhwYIF1da3Zs0a5s+fT0JCAlu3bmXevHkUFxfTp08fbr/99ipnQZ0yZQo7duygsLCQbdu2xfyK72jD4C1goXPOmVki0A8vFJq3Fonw/T9D+yPDrkSkablsVvVtya1qbm/drub2KHz00Ud89NFHZVfnbt68maKiIh588EGuvfZajjrqKMaPH1/jjWR27NjBW2+9xbfffgvA9u3beemll7jwwgsrzUi6evVqBg4cWDaXUEJCQo3bHjhwYNkMpLNmzeKTTz4hOTmZPXv2sH///ipnQb388st57rnn2LFjB1dddVW9/j5VifYA8h3+1celt728I+aVNFbHfB86HuwunyLSmPTq1YuhQ4eSl5dHXl4eS5cuJTExkZycHB544AE2btzIrFle4ETOJBrpmWeeYfLkycycOZOZM2cyb948/vKXvwBUmpG0W7duvPfee+zdu7dsWbt27di0aVPZ7+vXry/bduQspQ888AD33XcfN998MwUFBWX1V5wFdfTo0bz22mvMmzePc86p29BZTaLtGVSMuLRYF9JoFeyCNf+CQ/vCIT3CrkZEotC3b1+6du3KSSedRHp6OiNHjmTChAkMHz6clJQUWrVqxQ033ABAz549GTJkCP/85z/JzMws28aTTz5Z9oEM0LFjR5KTk/n000/LZiRNSEigd+/ePPTQQ/ziF79g6NChtGnThjFjxjBu3DiSkpKYOHEi6enpZb2GigYNGkROTg79+/ena9euANxyyy2MHTuWhx9+mJYtW/L3v/+dNm3acPjhh3PooYce9P4IdRHtrKXX4V19/CLeaaY7nHM3xryaWgh01tJIO76E/zkKzroLTro6+P2JNEGatTR4hYWFDBs2jFdffZWMjIyoXhPzWUudc/8LPAIcBswKOwgaVPqh0LaLzigSkdAsW7aMwYMHc/XVV0cdBLUV7RXI1zvn/gAsNLNEM7vSOfdoIBU1Rtk5msFURELTt29fPvgg2C+k0Q48nVf6xD+APCaYchqp7AHenc92fhV2JSIigYg2DMzM2vhPUomnA8hw4OKzL5r/rRxE6iqa44/ScGr77xHt2URTgX+Z2fvAIOAPtayraTu0L1z3EWR0C7sSkUYpNTWV/Px82rVrV+P59dIwnHPk5+eTmpoa9WuiDYO1wGvAEGA50Ad4rtYVNlWJyZDZPewqRBqt7OxsNm7cGPXkcBK81NRUsrOjn34/2jB4FngY72yiFcB3al9aE7f+Xfi/p+Hc//WuTBaRMklJSfTooetwmrJojxnsdc79FfjCOfc/wFEB1tQ47fgClj0NW1aEXYmISMxFGwZbzKwdkGZmY4DuwZXUSGX712joegMRaYaivejsQudcPjAF6Az8NNCqGqOMbtA6S9cbiEizVKvBb+fcVuB/AqqlcTPzTjFVz0BEmqHYz3bUnGUPgIREKNwXdiUiIjGl02Jq45TrYcgNYVchIhJz6hnUhi6mEZFmKrAwMLOpZjbfzBaZ2TERy5PN7HEze9PMZptZW3/5Y2b2jpnlmdnvgqqr3mbfCC/Gx10/RSR+BBIGZjYE6OicGwqMA+6NaB6Bd73CacBLwBX+8gzgbOdcbqOeIru4ANa8ASUlYVciIhIzQfUMzgRmADjnlgOHRLTtBEpvJ9QeKL1+PQ3YEVA9sZM9APZth/w1YVciIhIzQYVBBw58yAMUmVnpvt4GjjazFcBPgH/4yx2QZ2Zz/Z5FJWZ2lZktMbMloc2BUjqDqU4xFZFmJKgw2M6Bb/8AJc650nGVO4HfO+d6AxcB0wCcc2f5w0qXA3+qaqPOuWnOuRznXE5WVlZApR9EuyMgpa3CQESalaDCYCEwCsDMegMbI9q6AaV3idkCdPHXKz3N9VugMKC66i8hAfpfDB10v1cRaT6Cus5gFvBdM1uId4xgnJndA9zq/zzkDxslAb/0XzPHD4QWwK8Dqis2zrwj7ApERGIqkDDwh4TGV1h8k/+4GhhexWtOD6KWwBTuheJCSE0PuxIRkXrTRWd1sW8H3NUFPpgediUiIjGhMKiL1HTI7KYZTEWk2VAY1FXpDKa6CbiINAMKg7rKzoHdW2DbhrArERGpN4VBXeniMxFpRhQGddXhGDhjKnQ6IexKRETqTfczqKsWiXDytWFXISISE+oZ1Mfeb2HVLCgqCLsSEZF6URjUx2dvw3M/hi8/DrsSEZF6URjUR+cc71EHkUWkiVMY1Ef6odC2i8JARJo8hUF9ZefoSmQRafIUBvWVPQC2b4CdXx18XRGRRkqnltbXcaPhiDOhdYewKxERqTOFQX216eD9iIg0YRomioXVr8Hbfwi7ChGROlMYxMJ/82D+76C4KOxKRETqRGEQC9kDoHAPbFkRdiUiInWiMIiF7NKLzxaHW4eISB0pDGIho5t3NpGuNxCRJkphEAtm3lDRri1hVyIiUic6tTRWfvQktEgKuwoRkTpRzyBWFAQi0oQpDGKlpASe+wm8+6ewKxERqTWFQawkJMC3n8GaN8KuRESk1hQGsZQ9ADYu9XoJIiJNiMIglrIHQMF2yP807EpERGpFYRBL2QO8R93sRkSaGIVBLLU7HHoOg+TWYVciIlIrus4glhIS4OKZYVchIlJr6hkEoWi/ZjAVkSZFYRBrny+Gu7JhwzthVyIiEjWFQay1OxyKC3QQWUSaFIVBrLU6BNodoRlMRaRJCSwMzGyqmc03s0VmdkzE8mQze9zM3jSz2WbW1l9+vpktNLP3zWxMUHU1iOwBXs/AubArERGJSiBhYGZDgI7OuaHAOODeiOYRwBfOudOAl4ArzKw1MBE4HTgNmGRmqUHU1iCyc2D3Vti2PuxKRESiElTP4ExgBoBzbjlwSETbTiDTf94e2AoMAuY55wqcc7uB94GjAqoteD1zYfhtkNgy7EpERKISVBh0wPuQL1VkZqX7ehs42sxWAD8B/lHF+vkcCIwyZnaVmS0xsyVbt26t2Nx4tDsMhvw/SOsYdiUiIlEJKgy2U/7DvMQ5Vzp7253A751zvYGLgGlVrJ9J+XAAwDk3zTmX45zLycrKCqbyWNnzDax/N+wqRESiElQYLARGAZhZb2BjRFs34Cv/+RagC7AYGGFmSWbWCjgWWBVQbQ1j0f3w5LlQuC/sSkREDiqoMJgFJJvZQuD3wE1mdo+ZJQO3Avea2VvA88AvnXNfA0/gDSHNBn7jnGval/BmnwglhfDVx2FXIiJyUIHMTeQPCY2vsPgm/3E1MLyK1zwKPBpEPaHIzvEeN34AXU4MtxYRkYPQRWdBSfsOtO2qK5FFpElQGAQpO0dXIotIk6AprIN06i8B512JbBZ2NSIi1VIYBKlj77ArEBGJioaJgvbJi7DylbCrEBGpkXoGQXvvz5CYAkefG3YlIiLVUs8gaNkD4IsPdeczEWnUFAZBy86Bor2w5d9hVyIiUi2FQdCyB3iPut5ARBoxhUHQMrpC6w7w9ZqwKxERqZYOIAfNDK5ZAqltw65ERKRa6hk0BAWBiDRyCoOGsGMTPH8xrFsYdiUiIlVSGDSE1LbehWfrFoRdiYhIlRQGDSG5NXQ4Br7QpHUi0jgpDBpKdg5sXAolJQdfV0SkgelsooaSPQCWPg5fr4YOR3tXJW9bDy2S/Z8kaJEC3U7y1t/xJRTu8doSU/z2ZK+XISISYwqDhtL9FO/D/JCe3u//9xQs+Uv5dRJT4ZbN3vM3boePnyvf3qo93LjWe/7CpfDpGwdCokUyZHaDS1/12mffCJuXl28/pCecOdVrX/S/XuC0SPLDJhkyusHxY7z2FS/D/j3lX5/WETqd4LVv9q+oLgsyP6hKz5wqKYEEdTxFmgqFQUPJ7AY3rvM+eAGGToITr4Li/VC033t0xQfWH3A5HDbMW168H4oLISHin+vw0yGtU/n2lpkH2lskgSVA4V7Yu81rj7ynwpo3YNMyf/8FgINupxwIgzcmwzdry7+HI86CnzzvPX/qB7Drq/Ltx/4QRvkBd3fXAz2bFsmQmAzHXwBn3uHd3+GRIZCQVD5Men8P+l/i1fPq9eWDqEUS9BwGPYfC/t3w4VPl2xOT4Tt9oN1hXoh9uSzitf7r23SAlDQoKYaifd7yhETda0IEhUHDSmlz4HlaR++nOl1OrPneySf8tOZ9nfXbmtsvqTCtdkkxlERMpnfZbC9IigsPBE5yRP3n/8n7UC5tLyrwAq/UKb/wwqA0qIr3Q8fjvDZX4t0SNDLICrd764O3rXULyrcXFUBSKy8M9n4Lc26ikrPuhJMmwPbP4fGzK7ef+0cvbDYtg+mnHVheGhjnP+QF0ob3YebPKoRJMpwxBboM8I79vPPH8sN3LVJg4Dg4pIfXa/rP6+WDqkUy9BoBrQ6BbRvg6/9UGCJMhva9vG0W7PL+9pG9toQWNf97itSTwkA8CS3Kf+Ckfafm9Q8/veb2UyfWvK8Ln62+PTUdrl9efXtaJ6+XFRkWxfuhdZbXnt4ZLppZPsiKC72D+ADpneCMqVBcELFOIWT28NpT2kCnfhHb9tczf9irYDtsWVF+38X74bhRXhhsWgbzJleue/w7XhisngOv/bJy+3UfQWZ3WPwIzJtSvs0SYOKn0Lo9LLwPFk+v3HO6fK4XHh9Mh0//VaHnlArn3u9t698zvcCKDKrkNtDvIq/988Wwa0vlIcBOfb32HV9CSWHl412JydX/m0mjpzCQpichwftQrU5KG2+IrTrph8LJ11bf3vEYGPVY9e2HnQY/r2HiweMv9IbMKoZF2qFee+/veR+spT2qsjDrcGD7KemVw6705IF2R8DhwyuHXekwYsEu2PnlgR5VxSHC/7wOH1UI41btD4TB2/fD6lnl2zO7e2EF8I9xsG5+hb/ZsTB+kff8iZHw1Sfle0ad+8MPp/uv/5l3IWZkmHTqC6dc77W/dRcU7i7fnnU0HPVdr/2TF72hxtKgSkyGtl0g60iv/asKx8pKwyy5VfX/ZoI558KuoU5ycnLckiU6b1+kTpzzhgVLw6Sk2Ot1gDeMVXqcqbQ9IRG6n+y1r5nnh03EEF7LzANh8u6f4NvPygfZIYfBsF957S+Nq9zedRCc90ev/YEc2PGFX5c/dBl5POrOzrB/V/n30+9iOO8B731Nzqj8fgdNgBF3ekF5d5fKQ3Qn/RwG/xx258PT3z8w9Ffa3u9iOHqk12OaN+XA8F1pr+jIs6FzP9i1FVbMrLz9zv2hbWfYtx22rq7cq2vTEZJaevc9KSnyhwaDOQHDzJY653IqLlfPQCQemfkfSElAhdOVM7p6P9U5fHjN2z5pQs3tP3ik5vZrIr7klZR4oUDEl9bx70T0iPxAadXuQPuYp8ufmFG83+u5gBdqQyZWGCLc7w3vlWrznQPb3b8bir/xHgEKdnonX0QGWVEBtM32wmDbBphdxRDpDx/zhhE3LYO/nle5/cfPQ6+z4NPX4bkfH6i1NCx+/AJ0HQirZkP+p3DydTX/DetAPQMRkfpyzgvY4kK/VxU5xOeHRctM2PMNbPqw/BBe8X7omev1HL5eAytfrjwEOHCcd2r4Z4u8Xtlxo+pcanU9A4WBiEgcqS4MdFWQiIgoDERERGEgIiIoDEREBIWBiIigMBARERQGIiKCwkBERGjCF52Z2VZgfR1f3h74OoblNAV6z/FB7zk+1Oc9d3POZVVc2GTDoD7MbElVV+A1Z3rP8UHvOT4E8Z41TCQiIgoDERGJ3zCYFnYBIdB7jg96z/Eh5u85Lo8ZiIhIefHaMxARkQgKAxERib8wMLOpZjbfzBaZ2TFh1xM0M8sws+fMLM/MFphZj4O/qnkwsw/NbETYdTQUMzvR/zdeZGY3hl1P0Mzshoj/l08Iu56gmFmWmf3WzKb6vx9pZvP8931vrPYTV2FgZkOAjs65ocA4IGZ/yEasFXCDcy4XuAeo4gatzY+ZjQLahl1HQzGzJOA24HvOuZOdc78Lu6YgmVkGcB6QC1wCTAmznoDdBxQASf7v9wOXO+dOBrqb2cBY7CSuwgA4E5gB4JxbDhwSbjnBc85tcs5t8n/9FtgdZj0NwczSgIuAZ8KupQGdjXdF/gz/W2O/sAsKWDHe51cy3tW4W8MtJzjOuYuBBQBmlgikOuc+85v/DpwUi/0kxmIjTUgHyv9HU2RmCc65krAKaihm1hmvV/DzsGtpAH8E7gDOCbuQBnQE3pebkUA23peemHxINEbOuZ1mtgBYCbQBhodcUkPJAvIjfs8Hjo7FhuOtZ7AdyIz4vSROgmAk3hDClRG9hGbJzH4CbHDOfRB2LQ2sCJjrnCvyvzWWmJmFXFNgzOwcvGGTw4CjgD/6Q2XN3TYgI+L3TGLUK4q3MFgIjAIws97AxnDLCZ6Z9QHOdc6Nc87lH/QFTd+Pgd5m9hzev/UkMzsy5Joawrt4Q0WYWUeg0DXvi4i6AZv997gDSANSwy0peM65vUCK39MH+AEwLxbbjrdholnAd81sIbAT7yByczcCGGJmef7vG/wxyGbJOVc2NGRmtwPvOedWh1dRw3DOLTaz1Wa2CK+XcEPYNQXsCeAvZjYfSAEecc7tDLekBnMD8KKZFQD/dM6tjMVGdQWyiIjE3TCRiIhUQWEgIiIKAxERURiIiAgKAxERQWEgIiIoDEREhPi76EwkKmb2O+AUYDPQGrgWuB3oCLQEfuyc+6+ZvQe8hnf170y8idOGAyXACOdcgZktxZtoLBf4A3Ai0A/Y6Jz7kb+/5ypuu0HeqIhPPQORCszsDCDTOTcYGIM3ORjANc65YcCfgQv9ZVnAU865QcD5wH/9KdJXAMP8dXoCk/FC4LfAc/62W5vZUTVsW6TBqGcgUtkJwGwA59x+M/sEb8bbn5vZLqATUDrh39cR3+I/Axb5z9dxYEKx/zjntgGY2RcV1zGzDsBtVWxbpMGoZyBS2QZgCICZtQIG+b8vcs5NAj6KWLfifC5Vze9SblkVE8hdVM22RRqMegYilb0InGdm7+IFw3+BV4Gn/SmyV+FNBhcrbwS4bZGoaKI6kQrMrAXevS6cmbUF3gIGOOeKQy5NJDDqGYhU1gHvm3oC3g1UJikIpLlTz0BERHQAWUREFAYiIoLCQEREUBiIiAgKAxERAf4/XwGCXu4Wrz8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정확도를 그래프로 표현\n",
    "plt.plot(para_gamma, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_gamma, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"gamma\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gamma를 (0.001, 0.01, 0.1, 1, 10)으로 설정했을 때 gamma가 0.1 이상이면 train 데이터에서 과적합이 일어난다. 그래서 과적합을 방지하고자 **gamma를 0.001로 선택**하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 SVM 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\n",
      "Accuracy on training set: 0.995\n",
      "Accuracy on test set: 0.938\n",
      "\n",
      "Confusion matrix: \n",
      "[[91  6]\n",
      " [ 2 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.938     0.958        97\n",
      "           1      0.829     0.935     0.879        31\n",
      "\n",
      "    accuracy                          0.938       128\n",
      "   macro avg      0.904     0.937     0.918       128\n",
      "weighted avg      0.942     0.938     0.939       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_final = SVC(gamma = 0.01, C = 1, random_state = 1234)\n",
    "svc_final.fit(df_scaled_train_x, df_train_y)\n",
    "\n",
    "y_pred = svc_final.predict(df_scaled_test_x)\n",
    "print(y_pred)\n",
    "print()\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svc_final.score(df_scaled_train_x, df_train_y)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(svc_final.score(df_scaled_test_x, df_test_y)))\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "print(classification_report(df_test_y, y_pred, digits =3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> predict 메소드를 통해 목표변수 y의 범주를 보았더니 범주는 0, 1이다.  \n",
    "  \n",
    "> 파라미터를 선정 후 새로운 SVC 모델을 만들었더니 train 정확도가 99.5%, test 정확도가 93.8%이다. 즉 test 데이터 기준으로 정분류율은 95.2%이다.\n",
    "\n",
    "> 스케일링 전 -> 후 -> 스케일 후 파라미터 재설정   \n",
    "train 데이터의 정확도 : 88.5% -> 99.5% -> 99.5%  \n",
    "test 데이터의 정확도가 89.1% -> 96.1% -> 93.8%  \n",
    "\n",
    "> confusion matrix는 정분류, 오분류율을 나타내는 행렬이다. 행렬을 봤을 때,  \n",
    ">> 정확도는 예측을 제대로 하였는지 측도인데 120/128로 93.8%이므로 기존 모델보다 확실히 예측 성능이 좋아진 것을 알 수 있다. 즉 양성이라고 예측했을 때 실제 양성, 음성이라고 예측했을 때 실제 음성일 판단이 93.8% 맞다는 뜻이다.  \n",
    "  \n",
    ">> 유방암이 양성이라고 예측했을 때 실제로 양성일 확률인 정밀도는 29/35로 82.8%이므로 양성이라고 예측했는데 음성일 확률이 17.2%나 된다는 것이다. 양성이라고 예측했는데 실제로 음성이라면 환자로서는 돈과 시간, 감정을 소요하는 것이고 병원의 입장에서는 돈을 벌 수 있는 요인이 되었지만 이 모델에 따라 신뢰도를 잃을 수도 있으니 주의해야한다.   \n",
    "  \n",
    ">> 민감도는 29/31 = 93.5%이다. 민감도는 실제 양성인데 예측을 양성이라고 맞추는 경우이므로 93.5% 신뢰할 수 있다는 말이다.  \n",
    "  \n",
    ">> 직접 생성한 SVM 모델에 대해 스케일링 후 파라미터를 설정한 모델보다 스케일만 하고 기본 파라미터일 때의 정확도가 더 높았다. 그래서 파라미터를 재수정해서 모델을 구축할 필요를 느꼈다. 그리고 본인의 모델이 민감도나 정확도 측면에서는 괜찮지만 오진할 확률이 17.2%나 되기 때문에 이 모델의 정밀도를 올리는 방안을 찾을 필요가 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
